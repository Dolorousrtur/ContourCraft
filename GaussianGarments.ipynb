{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f9c380",
   "metadata": {},
   "source": [
    "# Gaussian Garment finetuning and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c1573",
   "metadata": {},
   "source": [
    "This notebook shows how to finetune a ContourCraft model and material using the data generated by Gaussian Garments. This process is described in the Gaussian Garments paper as Stage 4 (Finetuning behavior).\n",
    "\n",
    "Once you have finetuned the model, you will be able to generate trajectories with ContourCraft which then can be visualised as photorealistic garments using the Gaussian Garments inference script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b73575",
   "metadata": {},
   "source": [
    "## Convert Gaussian Garments data into ContourCraft format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6604528",
   "metadata": {},
   "source": [
    "First, let's convert the data that is used and generated by Gaussian Garments into the format used by the model finetuning process in ContourCraft.\n",
    "\n",
    "Before starting, make sure that\n",
    "* You have stored the input data for the Gaussian Garments following its [Data Preparation instructions](https://github.com/eth-ait/Gaussian-Garments/blob/main/DataPreparation.md)\n",
    "* You have run the first and second stages of Gaussian Garments so now you have folders `stage1` and `stage2` in the output directory for your subject,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0442c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gaugar import GauGarConverter\n",
    "from pathlib import Path\n",
    "from utils.defaults import DEFAULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0dafd",
   "metadata": {},
   "source": [
    "Here, you will need to set the paths to the Inputs and Outputs folders you used for Gaussian Garments. \n",
    "\n",
    "These paths have to be the same as the ones you have set in the defaults.py for Gaussian Garments. \n",
    "See [Gaussian Garments' Readme](https://github.com/eth-ait/Gaussian-Garments?tab=readme-ov-file#data-preparation) for details.\n",
    "\n",
    "Then, create the `GauGarConverter` object which will convert all the data to the ContourCraft format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs forder, same as DEFAULTS.data_root in Gaussian Garments\n",
    "gaugar_data_root = Path('/path/to/gaussian/garments/input/data')\n",
    "\n",
    "# Outpus forder, same as DEFAULTS.output_root in Gaussian Garments\n",
    "gaugar_output_root = Path('/path/to/gaussian/garments/output/data')\n",
    "\n",
    "body_model_root = Path(DEFAULTS.aux_data) / 'body_models'\n",
    "\n",
    "garment_dicts_dir = Path(DEFAULTS.aux_data) / 'garment_dicts' / 'finetune'\n",
    "checkpoint_path = Path(DEFAULTS.data_root) / 'trained_models' / 'contourcraft.pth'\n",
    "\n",
    "converter = GauGarConverter(gaugar_data_root, gaugar_output_root, body_model_root, garment_dicts_dir, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469d087",
   "metadata": {},
   "source": [
    "Now, set the name and the template sequence and frame for your subject. THese values should be the same as you have used for stages 1 and 2 of Gaussian Garments.\n",
    "\n",
    "If you did not use `subject_out` parameter, set it to `None`, then the `subject` value will be used for the `subject_out` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ab1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of the subject you used in Gaussian Garments\n",
    "subject = '{subject}' \n",
    "\n",
    "# the name of the output subject you used in Gaussian Garments\n",
    "# set to None if you want to use the same name as the input subject\n",
    "subject_out = None \n",
    "\n",
    "# gender of the SMPL-X model you used\n",
    "gender = 'female'\n",
    "\n",
    "# the template sequence and the template frame number\n",
    "# you used in stages 1 and 2 of Gaussian Garments\n",
    "template_sequence = '{sequence}'\n",
    "template_frame = {template_frame}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662bccd",
   "metadata": {},
   "source": [
    "Finally, convert the training data using the `converter.convert_subject` function.\n",
    "\n",
    "This function will perform 5 actions:\n",
    "1. Convert the SMPL-X parameters stored in `{gaugar_data_root}/{subject}/*/smplx/` into an .npz pose sequences of the same format used in AMASS CMU dataset. The sequences will be stored under `{gaugar_output_root}/{subject_out}/stage4/smplx/`\n",
    "2. Convert the garment mesh registrations created in stage 2 of Gaussian Garments and stored under `{gaugar_output_root}/{subject_out}/stage2/*/meshes` into .pkl mesh sequences and store them under  `{gaugar_output_root}/{subject_out}/stage4/registrations/`\n",
    "3. Import the .obj template mesh of the garment stored in `{gaugar_output_root}/{subject_out}/stage1/template_uv.obj` as a garment dictionary used by ContourCraft. The garment dictionary will be stored in `{garment_dicts_dir}/{subject_out}.pkl`\n",
    "4. Create .csv data lists used by the ContourCraft dataloader for finetuning, and store them under `{DEFAULTS.data_root}/aux_data/datasplits/finetuning/{subject_out}/`\n",
    "5. Create a ContourCraft configuration file for the finetuning and store it as `{DEFAULTS.project_dir}/configs/finetune/{subject_out}.csv` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.convert_subject(subject, gender, template_sequence, template_frame, subject_out=subject_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa00f6",
   "metadata": {},
   "source": [
    "### Finetune multiple garments with a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f0cac",
   "metadata": {},
   "source": [
    "If you want to finetune a single model and the material parameters for multiple garments at the same time, you'll first need to convert their data individually using the code above.\n",
    "\n",
    "Then, use the function `converter.prepare_multigarment` to create a configuration file and the datasplits for the multi-garment finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fd53f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# add all the subject names (subject_out) to the list\n",
    "subject_list = []\n",
    "subject_list.append('{subject_out_1}')\n",
    "subject_list.append('{subject_out_2}')\n",
    "subject_list.append('{subject_out_3}')\n",
    "\n",
    "# set the name of the experiment, it will be used to name the configuration file and the datasplits\n",
    "experiment_name = 'my_experiment'\n",
    "\n",
    "# create the configuration file and the datasplits\n",
    "converter.prepare_multigarment(subject_list, experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c4552b",
   "metadata": {},
   "source": [
    "## Finetune the ContourCraft model and material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e17447",
   "metadata": {},
   "source": [
    "Once you have converted all the data with the code above, you can start the finetuning procedure with the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99024651",
   "metadata": {},
   "source": [
    "`python train.py config=finetune/{subject_out}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd09327",
   "metadata": {},
   "source": [
    "The whole process should take around 24 hours depending on the hardware.\n",
    "\n",
    "The finetuned checkpoints will be stored in `{DEFAULTS.data_root}/trained_models/finetuning/{subject_out}/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99bd82",
   "metadata": {},
   "source": [
    "## Generate sequences with the finetuned model and material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b1bd9",
   "metadata": {},
   "source": [
    "Now you can create the simulation trajectories with the finetuned bahavior. To do that, first, set the variable `checkpoint_path` below to the path of the latest finetuning checkpoint, and load the runner and material objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbea4f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from utils.validation import load_runner_and_material_from_checkpoint\n",
    "from utils.arguments import load_params\n",
    "from utils.defaults import DEFAULTS\n",
    "from pathlib import Path\n",
    "from utils.common import move2device\n",
    "from utils.io import pickle_dump\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "config_name = 'finetune/base'\n",
    "models_dir = Path(DEFAULTS.data_root) / 'trained_models'\n",
    "checkpoint_path = models_dir / 'finetuning/{subject_out}/step_XXXXXXXXXX.pth'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "# load the config from a .yaml file and load .py modules specified there\n",
    "modules, experiment_config = load_params(config_name)\n",
    "\n",
    "# load a Runner object and the .py module it is declared in together with the material stack\n",
    "runner_module, runner, material_stack = load_runner_and_material_from_checkpoint(checkpoint_path, modules, experiment_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c06c7",
   "metadata": {},
   "source": [
    "Then, choose a SMPL-X pose sequence and set `sequence_path` to its path. It can be a pose sequence from the AMASS CMU dataset, or one of the pose sequences from your data, which we created in the first part of this notebook.\n",
    "\n",
    "After that, you can create a dataloader for this sequence and the `{subject_out}` garment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with the pose sequence\n",
    "from utils.validation import create_postcvpr_one_sequence_dataloader\n",
    "\n",
    "# If True, the SMPL(-X) poses are slightly modified to avoid hand-body self-penetrations. The technique is adopted from the code of SNUG \n",
    "separate_arms = True\n",
    "\n",
    "# To test the simulation with the SMPL-X body model\n",
    "CMU_path = '/path/to/AMASS/smplx/CMU'\n",
    "sequence_path =  Path(CMU_path) / '01/01_01_stageii.npz'\n",
    "sequence_loader = 'cmu_npz_smplx'\n",
    "garment_dicts_dir = Path(DEFAULTS.aux_data) / 'garment_dicts' / 'finetune' \n",
    "garment_name = subject_out\n",
    "gender = 'female'\n",
    "\n",
    "dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, sequence_loader=sequence_loader, \n",
    "                                            obstacle_dict_file=None, gender=gender, garment_dicts_dir=garment_dicts_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebca88d",
   "metadata": {},
   "source": [
    "... and generate the simulation trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534959e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = next(iter(dataloader))\n",
    "sequence = move2device(sequence, 'cuda:0')\n",
    "trajectories_dict = runner.valid_rollout(sequence, material_stack,  bare=True, n_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9403d0",
   "metadata": {},
   "source": [
    "Finally, save the trajectory to a .pkl file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_file = '/your/trajectory/path.pkl'\n",
    "pickle_dump(trajectories_dict, trajectory_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a97d9",
   "metadata": {},
   "source": [
    "Now you can create photorealistic renders of the trajectory by using the following command in the Gaussian Garments repository:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0241cd4",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /path/to/Gaussian-Garments/\n",
    "python inference.py --traj_path {trajectory_file}.pkl --output_path {directory_to_store_renders}\n",
    "``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

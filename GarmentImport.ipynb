{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f77a4a",
   "metadata": {},
   "source": [
    "## Add a garment aligned with canonical SMPL(-X) body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099be96a",
   "metadata": {},
   "source": [
    "\n",
    "To add a new garment, you should have an `.obj` file with the garment mesh that is **aligned with the canonical body model** (zero-pose and zero-shape) you want to use.\n",
    "\n",
    "*If you only have garment geometry aligned with an arbitrary SMPL(-X) body, see the section for this below.*\n",
    "\n",
    "We currently support [SMPL](https://smpl.is.tue.mpg.de/) and [SMPL-X](https://smpl-x.is.tue.mpg.de/) body models.\n",
    "\n",
    "Note: you will not be able to run LBS-initialized simulation with a body model that is different from the one you specify in this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a71000",
   "metadata": {},
   "source": [
    "First, create a .pkl file with your garment data using `add_garment_to_garments_dict` function. \n",
    "\n",
    "We call such .pkl files \"garment dicts\". They are the key entity used to store garment information for ContourCraft.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "Click for more details\n",
    "</summary>\n",
    "\n",
    "It builds a dictionary for the garment that contains:\n",
    "* `rest_pos`: \\[Nx3\\], positions of the vertices in canonical pose that are aligned to zero- pose and shape SMPL body.\n",
    "* `faces`: \\[Fx3\\], triplets of node indices that constitute each face\n",
    "* `node_type` \\[Nx1\\], node type labels (`0` for regular, `3` for \"pinned\"). By default, all nodes are regular, we show how to add \"pinned nodes\" later in this notebook\n",
    "* `lbs` dictionary with shape- and pose- blendshapes and skinning weights for the garment, sampled from SMPL(-X) model\n",
    "* `center` and `coarse_edges` info on long-range (coarse) edges used to build a hiererchical graph of the garment.\n",
    "\n",
    "To be able to start simulation from an arbitrary pose, we use linear blend-skinning (LBS) to initialize the garment geometry in the first frame. For each garment node we sample pose- and shape-blendshapes and skinning weights from the closest SMPL(-X) node in canonical pose.\n",
    "\n",
    "However, for loose garments such approach may result in overly-stretched triangles. Therefore, we use the approach introduced in [\\[Santesteban et al. 2021\\]](http://mslab.es/projects/SelfSupervisedGarmentCollisions/) and average skinning weights and blendshapes over many randomly sampled SMPL(-X) nodes around the given garment node.\n",
    "\n",
    "The parameter `n_samples_lbs` controls the number of random samples to use. We recommend setting it to 0 for tight-fitting garments (shirts, pants) and to 1000 for loose ones (skirts, dresses).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24dc6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from utils.mesh_creation import GarmentCreator, add_pinned_verts\n",
    "from utils.defaults import DEFAULTS\n",
    "\n",
    "\n",
    "garment_obj_path = os.path.join(DEFAULTS.aux_data, 'garment_meshes', 'smplx', 'cindy_020_combined.obj')\n",
    "\n",
    "body_models_root = os.path.join(DEFAULTS.aux_data, 'body_models')\n",
    "\n",
    "# Model type, either 'smpl' or 'smplx'\n",
    "model_type = 'smplx'\n",
    "\n",
    "# gender, either 'male`, `female` or `neutral`\n",
    "gender = 'female'\n",
    "\n",
    "garment_dicts_dir =  Path(DEFAULTS.aux_data) / 'garment_dicts' / model_type\n",
    "garment_name = 'cindy_020_combined_test'\n",
    "\n",
    "# Use approximate_center=True to create temlate faster. In the original paper code it was False\n",
    "gc = GarmentCreator(garment_dicts_dir, body_models_root, model_type, gender, \n",
    "                    n_samples_lbs=0, verbose=True, coarse=True, approximate_center=True)\n",
    "gc.add_garment(garment_obj_path, garment_name)\n",
    "\n",
    "# Now garment 'cindy_020_combined_test' is added to the garments_dict.pkl file and can be used in furter steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1f579",
   "metadata": {},
   "source": [
    "### Add pinned vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d6f5c",
   "metadata": {},
   "source": [
    "For some gaments, it is necessary to fix positions for a subset of nodes relative to the body. For example, fix the top ring of a skirt or pants to prevent it from falling off the body.\n",
    "\n",
    "To label a set of garment nodes as \"pinned\", you need to use `add_pinned_verts` function and provide it with the list of node indices that you want to pin.\n",
    "\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "How to get vertex indices in Blender\n",
    "</summary>\n",
    "\n",
    "One easy way of getting indices for a set of nodes, is by using [Blender](https://www.blender.org/). \n",
    "\n",
    "1. Open it, import the garment from the `.obj` file. \n",
    "2. Then in `Layout` tab press `Tab` to go into the editing mode. \n",
    "3. Select all vertices you want to pin. \n",
    "4. Then, go into `Scripting` tab and execute the following piece of code there.\n",
    "\n",
    "```python\n",
    "import bpy\n",
    "import bmesh\n",
    "\n",
    "obj = bpy.context.active_object\n",
    "bm = bmesh.from_edit_mesh(obj.data)    \n",
    "obj = bpy.context.active_object; bm = bmesh.from_edit_mesh(obj.data)    ; selected = [i.index for i in bm.verts if i.select == True]; print(selected)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "5. You will get a list of indices for the selected nodes.\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Below are pinned indices for the garment `cindy_020_combined`, replace them with yours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinned_indices = \\\n",
    "[   26,    27,    28,    36,    47,    56,    68,    69,    79,\n",
    "          93,    94,   103,   121,   130,   151,   161,   185,   197,\n",
    "         222,   237,   262,   279,   280,   307,   326,   353,   372,\n",
    "         402,   422,   455,   456,   478,   513,   538,   576,   603,\n",
    "         641,   670,   706,   738,   778,   812,   855,   891,   936,\n",
    "         973,  1020,  1061,  1109,  1151,  1200,  1243,  1293,  1339,\n",
    "        1390,  1439,  1492,  1543,  1597,  1651,  1706,  1761,  1821,\n",
    "        1878,  1936,  1994,  2052,  2112,  2176,  2238,  2306,  2369,\n",
    "        2439,  2508,  2576,  2644,  2713,  2719,  2784,  2858,  2926,\n",
    "        3001,  3071,  3148,  3218,  3296,  3368,  3448,  3522,  3607,\n",
    "        3687,  3770,  3850,  3934,  4016,  4102,  4187,  4269,  6567,\n",
    "        6626,  7071,  7368,  7577,  7804,  7920,  8040,  8460,  8550,\n",
    "        8632,  8992,  9065,  9137, 11694, 11695, 11700, 11706, 11712,\n",
    "       11715, 11726, 11731, 11735, 11739, 11743, 11747, 11755, 11761,\n",
    "       11770, 11779, 11792, 11797, 11802, 11814, 11819, 11824, 11829,\n",
    "       11851, 11857]\n",
    "\n",
    "gc.add_pinned_verts(garment_name, pinned_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b42a2",
   "metadata": {},
   "source": [
    "## Adding garments aligned with an arbitrary SMPL(-X) pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2cfb0",
   "metadata": {},
   "source": [
    "You can also import a garment aligned with an arbitrary SMPL(-X) body. \n",
    "\n",
    "To do this you will need:\n",
    "* a .pkl file containing SMPL(-X) parameters (details below), and\n",
    "* an .obj file with the garment mesh which is aligned with this body\n",
    "\n",
    "The process runs in two steps:\n",
    "1. We un-pose and un-shape the garment using the linear-blend skinning weights from the body model. This step alignes the garment with the canonical body geometry, but may introduce very unrealistic geometries.\n",
    "2. We simulate the garment over the canonical body to relax the artifacts. Here (and in subsequent simulations) we use the original garment geometry as the \"resting\" one. After the relaxation this garment is imported to a .pkl garment dict with the usual procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062954d4",
   "metadata": {},
   "source": [
    "We provide the example garment geometries and the body poses for both SMPL and SMPL-X models in `DEFAULTS.data_root/examples/unpose`.\n",
    "\n",
    "The garment geometries are stored in simple .obj files.\n",
    "\n",
    "The pose sequences are stored as .pkl files that contain dictionaries with the SMPL(-X) parameters. Below you can see the names and the shapes of the parameters in these files:\n",
    "\n",
    "<details>\n",
    "  <summary>for SMPL</summary>\n",
    "\n",
    "\n",
    "```python\n",
    "\"betas\": (1, 10)\n",
    "\"transl\": (1, 3)\n",
    "\"global_orient\": (1, 3)\n",
    "\"body_pose\": (1, 69)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>for SMPL-X</summary>\n",
    "\n",
    "\n",
    "```python\n",
    "\"betas\": (1, 10)\n",
    "\"transl\": (1, 3)\n",
    "\"global_orient\": (1, 3)\n",
    "\"body_pose\": (1, 63)\n",
    "\"jaw_pose\": (1, 3)\n",
    "\"left_hand_pose\": (1, 45)\n",
    "\"right_hand_pose\": (1, 45)\n",
    "\"leye_pose\": (1, 3)\n",
    "\"reye_pose\": (1, 3)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "You can use functions `create_smpl_pose_file` and `create_smplx_pose_file` in `utils/mesh_creation.py` to create such .pkl files from a frame of an AMASS pose sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mesh_creation import GarmentCreator\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils.defaults import DEFAULTS\n",
    "\n",
    "body_models_root = Path(DEFAULTS.aux_data) /  'body_models'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ================  Test for SMPL-X ============\n",
    "model_type = 'smplx'\n",
    "gender = 'male'\n",
    "\n",
    "# Directory, where garment dictionaries are stored\n",
    "garment_dicts_dir =  Path(DEFAULTS.aux_data) / 'garment_dicts' / 'smplx'\n",
    "\n",
    "# Path to the garment object file\n",
    "garment_obj_path = Path(DEFAULTS.data_root) / 'examples' / 'unpose' / 'smplx_garment.obj'\n",
    "\n",
    "# Path to the body parameters file\n",
    "body_params_file = Path(DEFAULTS.data_root) / 'examples' / 'unpose' / 'smplx_posed.pkl'\n",
    "# # ============================================\n",
    "\n",
    "# ================  Test for SMPL ============\n",
    "# model_type = 'smpl'\n",
    "# gender = 'male'\n",
    "# garment_dicts_dir =  Path(DEFAULTS.aux_data) / 'garment_dicts' / 'smpl'\n",
    "# garment_obj_path = Path(DEFAULTS.data_root) / 'examples' / 'unpose' / 'smpl_garment.obj'\n",
    "# body_params_file = Path(DEFAULTS.data_root) / 'examples' / 'unpose' / 'smpl_posed.pkl'\n",
    "# ============================================\n",
    "\n",
    "\n",
    "# Name of the garment, the garment dict will be saved as {garment_dicts_dir}/{garment_name}.pkl\n",
    "garment_name = 'unposed_garment2'\n",
    "\n",
    "# Path to the ContourCraft checkpoint\n",
    "models_dir = Path(DEFAULTS.data_root) / 'trained_models'\n",
    "checkpoint_path = models_dir / 'contourcraft.pth'\n",
    "\n",
    "gc = GarmentCreator(garment_dicts_dir, body_models_root, model_type, gender, \n",
    "                    n_samples_lbs=0, verbose=True, coarse=True, approximate_center=True)\n",
    "\n",
    "relaxation_trajectory = gc.add_posed_garment(garment_obj_path, garment_name, body_params_file, \n",
    "                                             checkpoint_path, n_relaxation_steps=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a7f35",
   "metadata": {},
   "source": [
    "Now you can also save the relaxation trajectory and see in in AITViewer for debugging purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b7136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_dump\n",
    "out_trajectory_path = Path(DEFAULTS.data_root) / 'temp' / 'relax_trajectory.pkl'\n",
    "pickle_dump(relaxation_trajectory, out_trajectory_path)\n",
    "print('Relaxation trajectory saved to', out_trajectory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f867dca6",
   "metadata": {},
   "source": [
    "To see it in AITviewer, run:\n",
    "```\n",
    "python utils/show.py rollout_path=PATH_TO_SEQUENCE\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

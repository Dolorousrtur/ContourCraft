{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load, pickle_dump\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garment_dict_path = '/local/home/agrigorev/Data/02_Projects/hood_data/aux_data/garments_dict.pkl'\n",
    "# garment_dict_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/train_wdetailed2.pkl'\n",
    "garment_dict_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/garment_dicts/outfit_dict2_faulty.pkl'\n",
    "\n",
    "garments_dict = pickle_load(garment_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o0110::00152_lower 55\n",
      "o0110::00170_upper 55\n",
      "o0110::00152_outer 55\n",
      "o0160::00152_lower 55\n",
      "o0160::00176_upper 55\n",
      "o0160::00152_outer 55\n",
      "o0160::10006_outer 55\n",
      "o0170::00152_lower 55\n",
      "o0170::00176_upper 55\n",
      "o0170::00152_outer 55\n",
      "o0170::10004_outer 55\n",
      "o0190::00148_upper 55\n",
      "o0190::00152_outer 55\n",
      "o0200::00176_lower 55\n",
      "o0200::00190_upper 55\n",
      "o0200::00152_outer 55\n",
      "o0210::00170_lower 55\n",
      "o0210::00152_outer 55\n",
      "o0210::00148_outer 55\n",
      "o0210::00176_upper 55\n",
      "o0051::10006_outer 55\n",
      "o0051::00148_upper 55\n",
      "o0050::00148_upper 55\n",
      "o0050::10006_outer 55\n",
      "o0161::00152_lower 55\n",
      "o0161::00176_upper 55\n",
      "o0161::10006_outer 55\n",
      "o0161::00152_outer 55\n",
      "o0100::00170_lower 55\n",
      "o0100::00190_upper 55\n",
      "o0100::10006_outer 55\n",
      "o0230::00176_lower 55\n",
      "o0230::00134_upper 55\n",
      "o0230::10006_outer 55\n",
      "o0240::00152_lower 55\n",
      "o0240::00170_upper 55\n",
      "o0240::00134_upper 55\n",
      "o0240::10006_outer 55\n",
      "o0150::00148_upper 55\n",
      "o0150::00190_upper 55\n",
      "o0150::10006_outer 55\n",
      "o0220::00176_upper 55\n",
      "o0220::10006_outer 55\n",
      "o0220::00152_outer 55\n",
      "o0250::00176_lower 55\n",
      "o0250::00176_upper 55\n",
      "o0250::10006_outer 55\n",
      "o0250::10004_outer 55\n",
      "o0220::00176_lower 55\n",
      "o0241::00152_lower 55\n",
      "o0241::00170_upper 55\n",
      "o0241::10006_outer 55\n",
      "o9000::00176_lower 55\n",
      "o9000::00170_upper 55\n",
      "o9000::00134_upper 55\n",
      "o9000::00152_outer 55\n",
      "o9000::00148_outer 55\n",
      "o0242::00170_lower 55\n",
      "o0242::00170_upper 55\n",
      "o0242::10006_outer 55\n",
      "o0040::00148_upper 55\n",
      "o0040::00148_outer 55\n",
      "o9000::10006_outer 55\n",
      "o0300::00176_lower 55\n",
      "o0300::00176_upper 55\n",
      "o0300::00176_outer 55\n",
      "o0310::00152_lower 55\n",
      "o0310::00176_upper 55\n",
      "o0310::00152_outer 55\n",
      "o0320::00152_lower 55\n",
      "o0320::00190_upper 55\n",
      "o0320::10006_outer 55\n",
      "o0120::00148_upper 55\n",
      "o0120::00176_outer 55\n",
      "o0130::00170_lower 55\n",
      "o0130::00170_upper 55\n",
      "o0130::00148_outer 55\n",
      "o0140::00148_upper 55\n",
      "o0140::00190_upper 55\n",
      "o0260::00176_lower 55\n",
      "o0260::00134_upper 55\n",
      "o0260::00122_outer 55\n",
      "o0280::00152_lower 55\n",
      "o0280::00190_upper 55\n",
      "o0280::00122_outer 55\n",
      "o0400::00152_lower 55\n",
      "o0400::00152_outer 55\n",
      "o0410::00170_lower 55\n",
      "o0410::00170_upper 55\n",
      "o0420::00152_lower 55\n",
      "o0420::00176_lower 55\n",
      "o0420::00134_upper 55\n"
     ]
    }
   ],
   "source": [
    "out_dir = Path(\"/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/garment_dicts\")\n",
    "\n",
    "for k, v in garments_dict.items():\n",
    "    v['name'] = k\n",
    "\n",
    "    lbs_shape = v['lbs']['lbs_weights'].shape[-1]\n",
    "\n",
    "    # bmodel = 'smpl' if lbs_shape == 24 else 'smplx'\n",
    "    bmodel = 'faulty'\n",
    "    out_path = out_dir / bmodel /  f\"{k}.pkl\"\n",
    "\n",
    "    print(k, lbs_shape)\n",
    "    pickle_dump(v, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference with individual garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOOD_PROJECT =  \"/local/home/agrigorev/Workdir/00_Projects/contourcraft_private\"\n",
    "HOOD_DATA = \"/local/home/agrigorev/Data/02_Projects/ccraft_data\"\n",
    "\n",
    "os.environ[\"HOOD_PROJECT\"] = HOOD_PROJECT\n",
    "os.environ[\"HOOD_DATA\"] = HOOD_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/utils/validation.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "from utils.validation import apply_material_params\n",
    "from utils.validation import load_runner_from_checkpoint\n",
    "from utils.arguments import load_params\n",
    "from utils.common import move2device\n",
    "from utils.io import pickle_dump\n",
    "from utils.defaults import DEFAULTS\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Set material paramenters, see configs/cvpr.yaml for the training ranges for each parameter\n",
    "material_dict = dict()\n",
    "material_dict['density'] = 0.20022\n",
    "material_dict['lame_mu'] = 23600.0\n",
    "material_dict['lame_lambda'] = 44400\n",
    "material_dict['bending_coeff'] = 3.962e-05\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "models_dir = Path(DEFAULTS.data_root) / 'trained_models'\n",
    "\n",
    "# Choose the model and the configuration file\n",
    "config_name = 'ccraft_indgd'\n",
    "checkpoint_path = models_dir / 'contourcraft.pth'\n",
    "\n",
    "\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/temp/restangles_50K.pth'\n",
    "\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/temp/regular_56K.pth'\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/temp/restangles_56K.pth'\n",
    "\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/temp/final_from_orig_pretrain.pth'\n",
    "\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/server4-data/experiments/wandb/run-20250219_193026-ibz41e57/checkpoints/step_0000036000.pth'\n",
    "\n",
    "#regular s2\n",
    "# checkpoint_path = '/local/home/agrigorev/mpi-fast/experiments/wandb/run-20250225_181712-fb23wp24/checkpoints/step_0000051200.pth'\n",
    "\n",
    "\n",
    "# new_final\n",
    "checkpoint_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/temp/new_final.pth'\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "# load the config from .yaml file and load .py modules specified there\n",
    "modules, experiment_config = load_params(config_name)\n",
    "\n",
    "# modify the config to use it in validation \n",
    "experiment_config = apply_material_params(experiment_config, material_dict)\n",
    "\n",
    "# load Runner object and the .py module it is declared in\n",
    "runner_module, runner = load_runner_from_checkpoint(checkpoint_path, modules, experiment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with the pose sequence\n",
    "from utils.validation import create_postcvpr_one_sequence_dataloader\n",
    "\n",
    "# If True, the SMPL(-X) poses are slightly modified to avoid hand-body self-penetrations. The technique is adopted from the code of SNUG \n",
    "separate_arms = True\n",
    "\n",
    "# path to the pose sequence file\n",
    "sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smplx/CMU//01/01_01_stageii.npz'\n",
    "# sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU//01/01_01_poses.npz'\n",
    "\n",
    "# name of the garment to simulate\n",
    "# garment_name = 'cindy_020_combined_test'\n",
    "# garment_name = 'ben_004::top_coat,ben_004::scarf'\n",
    "# garment_name = 'smplx/celina_002_combined'\n",
    "# garment_name = 'smplx/cindy_020_combined'\n",
    "garment_name = 'smplx/aaron_022::top_coat,smplx/aaron_022::bottom_pants'\n",
    "\n",
    "\n",
    "garment_name = 'faulty/o0040::00148_outer,faulty/o0040::00148_upper'\n",
    "\n",
    "# It can be a comma-separated list of individual garments\n",
    "# garment_name = 'cindy_020::bottom_skirt, cindy_020::top_blouse'\n",
    "\n",
    "garment_dict_file = 'garments_dict.pkl'\n",
    "\n",
    "\n",
    "# gender of the body model, sould be the same as the one used to create the garment\n",
    "gender = 'female'\n",
    "# gender = 'male'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "# Choose the type of the pose sequence you want to use: 'cmu_npz_smpl', 'cmu_npz_smplx', 'hood_pkl'\n",
    "\n",
    "# to use AMASS SMPL-X pose sequence\n",
    "sequence_loader = 'cmu_npz_smplx'\n",
    "\n",
    "# to use AMASS SMPL pose sequence\n",
    "# sequence_loader = 'cmu_npz_smpl'\n",
    "\n",
    "# to use our (legacy) SMPL pose sequence\n",
    "# sequence_loader = 'hood_pkl'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, \n",
    "                                            garment_dict_file, sequence_loader=sequence_loader, \n",
    "                                            obstacle_dict_file=None, config=\"ccraft_indgd\", gender=gender)\n",
    "# dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, \n",
    "#                                             garment_dict_file, sequence_loader=sequence_loader, \n",
    "#                                             obstacle_dict_file=None, config=\"ccraft_indgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path /local/home/agrigorev/Data/00_Datasets/AMASS/smplx/CMU//01\n",
      "filepath /local/home/agrigorev/Data/00_Datasets/AMASS/smplx/CMU//01/01_01_stageii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module utils.warp_u.proximity b91666f load on device 'cuda:0' took 0.77 ms  (cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacity of 11.65 GiB of which 196.00 MiB is free. Including non-PyTorch memory, this process has 9.50 GiB memory in use. Of the allocated memory 8.97 GiB is allocated by PyTorch, and 384.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\n\u001b[1;32m      2\u001b[0m sequence \u001b[38;5;241m=\u001b[39m move2device(sequence, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m trajectories_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft.py:140\u001b[0m, in \u001b[0;36mRunner.valid_rollout\u001b[0;34m(self, sequence, n_steps, bare, record_time, safecheck)\u001b[0m\n\u001b[1;32m    138\u001b[0m st \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 140\u001b[0m trajectories, metrics_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafecheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafecheck\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_time:\n\u001b[1;32m    144\u001b[0m     total_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m st_time\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft.py:217\u001b[0m, in \u001b[0;36mRunner._rollout\u001b[0;34m(self, sample, start_idx, n_steps, progressbar, bare, safecheck)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TorchTimer(metrics_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhood_time\u001b[39m\u001b[38;5;124m'\u001b[39m, start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend):\n\u001b[1;32m    216\u001b[0m     sample_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(sample_step)\n\u001b[0;32m--> 217\u001b[0m ncoll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafecheck_solver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_tritri_collisions2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverts_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred_pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m metrics_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mncoll\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ncoll)\n\u001b[1;32m    220\u001b[0m prev_out_sample \u001b[38;5;241m=\u001b[39m sample_step\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/utils/impulses.py:329\u001b[0m, in \u001b[0;36mCollisionSolver.calc_tritri_collisions2\u001b[0;34m(sample, obj_key, verts_key, threshold)\u001b[0m\n\u001b[1;32m    326\u001b[0m faces \u001b[38;5;241m=\u001b[39m sample[obj_key]\u001b[38;5;241m.\u001b[39mfaces_batch\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    327\u001b[0m pos \u001b[38;5;241m=\u001b[39m pos\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[0;32m--> 329\u001b[0m collisions_tri \u001b[38;5;241m=\u001b[39m \u001b[43mfind_close_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenetrating_mask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sample[obj_key]:\n\u001b[1;32m    332\u001b[0m     penetrating_mask \u001b[38;5;241m=\u001b[39m sample[obj_key]\u001b[38;5;241m.\u001b[39mpenetrating_mask\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/utils/selfcollisions.py:57\u001b[0m, in \u001b[0;36mfind_close_faces\u001b[0;34m(vertices, faces, threshold)\u001b[0m\n\u001b[1;32m     55\u001b[0m triangles \u001b[38;5;241m=\u001b[39m vertices[faces]\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     56\u001b[0m bboxes, tree \u001b[38;5;241m=\u001b[39m collisions\u001b[38;5;241m.\u001b[39mbvh(triangles)\n\u001b[0;32m---> 57\u001b[0m face_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mcollisions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_collisions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriangles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     58\u001b[0m face_pairs \u001b[38;5;241m=\u001b[39m face_pairs[face_pairs[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m face_pairs\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 154.00 MiB. GPU 0 has a total capacity of 11.65 GiB of which 196.00 MiB is free. Including non-PyTorch memory, this process has 9.50 GiB memory in use. Of the allocated memory 8.97 GiB is allocated by PyTorch, and 384.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "sequence = next(iter(dataloader))\n",
    "sequence = move2device(sequence, 'cuda:0')\n",
    "trajectories_dict = runner.valid_rollout(sequence,  bare=True, n_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_dump\n",
    "\n",
    "out_path = '/local/home/agrigorev/Data/temp/new_final.pkl'\n",
    "pickle_dump(trajectories_dict, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check datalists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def proc_id(old_id):\n",
    "    parts = old_id.split('_')\n",
    "\n",
    "    person_id = parts[-2]\n",
    "    seq_id = parts[-1]\n",
    "\n",
    "    relative_path = f\"{person_id}/{person_id}_{seq_id}_poses.npz\"\n",
    "\n",
    "    return relative_path\n",
    "\n",
    "def get_lengths(amass_root, id_list):\n",
    "    ids_unique = list(set(id_list))\n",
    "    lengths = {}\n",
    "\n",
    "    for id in ids_unique:\n",
    "        path = f\"{amass_root}/{id}\"\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Path {id} does not exist\")\n",
    "            lengths[id] = -1\n",
    "            continue\n",
    "\n",
    "        data = dict(np.load(path, allow_pickle=True))\n",
    "        l = data['poses'].shape[0]\n",
    "        lengths[id] = l     \n",
    "\n",
    "    return lengths   \n",
    "\n",
    "datasplit_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "datasplit = pd.read_csv(datasplit_path)\n",
    "\n",
    "datasplit_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits_unique = list(set(datasplit['garment']))\n",
    "garments_unique = []\n",
    "for ou in outfits_unique:\n",
    "    garments_unique += ou.split(',')\n",
    "garments_unique = sorted(list(set(garments_unique)))\n",
    "\n",
    "def get_gender(garment):\n",
    "    gender = 'female'\n",
    "    for p in ['aaron', 'ben']:\n",
    "        if p in garment:\n",
    "            gender = 'male'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 104/104_04_poses.npz does not exist\n",
      "Path 26/26_11_poses.npz does not exist\n",
      "Path 104/104_53_poses.npz does not exist\n",
      "Path 104/104_17_poses.npz does not exist\n",
      "Path 104/104_11_poses.npz does not exist\n",
      "Path 144/144_30_poses.npz does not exist\n"
     ]
    }
   ],
   "source": [
    "ids_old = datasplit['id'].values\n",
    "ids_new = [proc_id(old_id) for old_id in ids_old]\n",
    "\n",
    "amass_root = '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU'\n",
    "length_dict = get_lengths(amass_root, ids_new)\n",
    "\n",
    "new_df_dict = defaultdict(list)\n",
    "\n",
    "for i, id in enumerate(ids_new):\n",
    "    l = length_dict[id]\n",
    "\n",
    "    if l > 0:\n",
    "        new_df_dict['id'].append(id)\n",
    "        new_df_dict['length'].append(length_dict[id])\n",
    "\n",
    "        garment = datasplit['garment'].values[i]\n",
    "        new_df_dict['garment'].append(garment)\n",
    "\n",
    "\n",
    "        gender = get_gender(garment)\n",
    "        new_df_dict['gender'].append(gender)\n",
    "\n",
    "datasplit_new = pd.DataFrame()\n",
    "\n",
    "for k, v in new_df_dict.items():\n",
    "    datasplit_new[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_new.to_csv('/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from utils.defaults import DEFAULTS\n",
    "\n",
    "from utils.arguments import load_params, create_modules\n",
    "\n",
    "s = 59\n",
    "torch.manual_seed(s)\n",
    "np.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/utils/arguments.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED CHECKPOINT FROM /local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/temp/regular_56K.pth\n",
      "optimizer LOADED!\n",
      "scheduler LOADED!\n"
     ]
    }
   ],
   "source": [
    "# modules, config = load_params(config_name='ccraft_train_s1_debug')\n",
    "from utils.arguments import load_from_checkpoint\n",
    "\n",
    "\n",
    "modules, config = load_params(config_name='ccraft_train_s2_debug')\n",
    "dataloader_ms, runner_module, runner, aux_modules = create_modules(modules, config)\n",
    "\n",
    "checkpoint_path = Path(DEFAULTS.data_root) / 'trained_models' / 'contourcraft.pth'\n",
    "\n",
    "#restangles\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/server4-data/experiments/wandb/run-20250219_193026-ibz41e57/checkpoints/step_0000050000.pth'\n",
    "\n",
    "# regular\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/server4-data/experiments/wandb/run-20250220_142545-274x63w1/checkpoints/step_0000050000.pth'\n",
    "\n",
    "# checkpoint_path = 'trained_models/orig_pretrain.pth'\n",
    "checkpoint_path = 'trained_models/temp/regular_56K.pth'\n",
    "\n",
    "config.restart.checkpoint_path = checkpoint_path\n",
    "\n",
    "# if config.experiment.checkpoint_path is not None and os.path.exists(config.experiment.checkpoint_path):\n",
    "#     sd = torch.load(config.experiment.checkpoint_path)\n",
    "\n",
    "#     if 'training_module' in sd:\n",
    "#         runner.load_state_dict(sd['training_module'])\n",
    "\n",
    "#         for k, v in aux_modules.items():\n",
    "#             if k in sd:\n",
    "#                 print(f'{k} LOADED!')\n",
    "#                 v.load_state_dict(sd[k])\n",
    "#     else:\n",
    "#         runner.load_state_dict(sd)\n",
    "#     print('LOADED:', config.experiment.checkpoint_path)\n",
    "\n",
    "runner, aux_modules = load_from_checkpoint(config, runner, aux_modules)\n",
    "dataloaders_dict = dict()\n",
    "for dataloader_name, dataloader in dataloader_ms.items():\n",
    "    dataloaders_dict[dataloader_name] = dataloader.create_dataloader()\n",
    "\n",
    "dataloader_short = dataloaders_dict['short']\n",
    "dataloader_long = dataloaders_dict['long']\n",
    "\n",
    "sample_short = next(iter(dataloader_short))\n",
    "sample_long = next(iter(dataloader_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s2_debug:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garment name ben_004::top_coat,ben_004::scarf\n",
      "sequence_name 144/144_26_poses.npz\n",
      "roll_steps 100\n",
      "Module utils.warp_u.proximity b91666f load on device 'cuda:0' took 5.44 ms  (cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s2_debug:  50%|█████     | 1/2 [01:06<01:06, 66.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long saved to /local/home/agrigorev/Data/temp/debug/long_50001.pkl\n",
      "garment name ben_004::top_coat,ben_004::scarf\n",
      "sequence_name 144/144_26_poses.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s2_debug: 100%|██████████| 2/2 [01:14<00:00, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short saved to /local/home/agrigorev/Data/temp/debug/short_50002.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = runner_module.run_epoch(runner, aux_modules, dataloaders_dict, config, None,\n",
    "                                global_step=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load\n",
    "\n",
    "seq_id = 'long_50001'\n",
    "traj_path_new = f'/local/home/agrigorev/Data/temp/debug/{seq_id}.pkl'\n",
    "# traj_path_old = f'/local/home/agrigorev/Data/temp/debug_old/{seq_id}.pkl'\n",
    "traj_path_old = f'/local/home/agrigorev/Data/temp/debug_old/long_50005.pkl'\n",
    "\n",
    "traj_new = pickle_load(traj_path_new)\n",
    "traj_old = pickle_load(traj_path_old)\n",
    "\n",
    "traj_old['metrics'] = {k[5:]: v for k, v in traj_old['metrics'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impulse_iters 3.3535353535353534 0.5757575757575758\n",
      "impulse_stencil_ncoll 18.09090909090909 4.848484848484849\n",
      "riz_iters 0.030303030303030304 0.0\n",
      "riz_itersmax_riz_size 14 0\n",
      "hood/stretching_energy_loss 0.46309065982699393 0.3990580676496029\n",
      "hood/bending_energy_loss 0.05469794849625032 0.05483933967601842\n",
      "hood/inertia_loss 0.005737926782021532 0.005145852939167525\n",
      "hood/gravitational_energy_loss 5.911851909756661 0.24605285611003638\n",
      "hood/collision_penalty_loss 1.5756199880712665e-06 3.8512562416271974e-08\n",
      "hood/repulsion_loss 0.0010708723684215546 0.00103699604091683\n"
     ]
    }
   ],
   "source": [
    "for k in traj_new['metrics'].keys():\n",
    "    if k in traj_old['metrics']:\n",
    "        print(k, traj_new['metrics'][k], traj_old['metrics'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hood/stretching_energy_loss': 0.3489467564970255,\n",
       " 'hood/bending_energy_loss': 0.052061445642502806,\n",
       " 'hood/inertia_loss': 0.005703017642517807,\n",
       " 'hood/gravitational_energy_loss': 5.70411994278431,\n",
       " 'hood/collision_penalty_loss': 1.7778491685324115e-06,\n",
       " 'hood/repulsion_loss': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_new['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long/hood/stretching_energy_loss': 0.3008002529293299,\n",
       " 'long/hood/inertia_loss': 0.005532875381904887,\n",
       " 'long/hood/gravitational_energy_loss': 0.18318553576245905,\n",
       " 'long/hood/bending_energy_loss': 0.06113392335770186,\n",
       " 'long/hood/collision_penalty_loss': 3.893926055232442e-08,\n",
       " 'long/hood/repulsion_loss': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_old['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make debug datalists for new and old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "old_datasplit = pd.read_csv(old_df_path)\n",
    "\n",
    "\n",
    "new_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv'\n",
    "new_datasplit = pd.read_csv(new_df_path)\n",
    "new_row = new_datasplit.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2730"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(old_datasplit.length.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_datasplit_f1 = old_datasplit[old_datasplit.garment=='ben_004::top_coat,ben_004::scarf']\n",
    "old_row = old_datasplit_f1.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>garment</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29171</th>\n",
       "      <td>32707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape14_144_26</td>\n",
       "      <td>1480</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0                     id  length  \\\n",
       "29171         32707         NaN  tshirt_shape14_144_26    1480   \n",
       "\n",
       "                                garment gender  \n",
       "29171  ben_004::top_coat,ben_004::scarf   male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row.to_csv('/local/home/agrigorev/Data/temp/datasplits/new.csv', index=False)\n",
    "old_row.to_csv('/local/home/agrigorev/Data/temp/datasplits/old.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "a = Batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.short_is_training = True\n",
    "self.mcfg.long_is_training = True\n",
    "self.mcfg.nocollect_after = 2\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "\n",
    "```\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.nocollect_after = 2\n",
    "self.mcfg.short_is_training = True\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

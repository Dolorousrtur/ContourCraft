{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load, pickle_dump\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garment_dict_path = '/local/home/agrigorev/Data/02_Projects/hood_data/aux_data/garments_dict.pkl'\n",
    "garment_dict_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/train_wdetailed2.pkl'\n",
    "\n",
    "garments_dict = pickle_load(garment_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt_unzipped 24\n",
      "dress 24\n",
      "tshirt 24\n",
      "longsleeve 24\n",
      "tank 24\n",
      "pants 24\n",
      "shorts 24\n",
      "beatrice_019::bottom 24\n",
      "beatrice_019::top_shirt 24\n",
      "beatrice_019::top_apron 24\n",
      "aaron_009::bottom 24\n",
      "aaron_009::top 24\n",
      "aneko_015::bottom 24\n",
      "aneko_015::top_shirt 24\n",
      "aneko_015::top_jacket 24\n",
      "aaron_013::bottom 24\n",
      "aaron_013::top 24\n",
      "ben_004::bottom 24\n",
      "ben_004::top_vest 24\n",
      "ben_004::scarf 24\n",
      "ben_004::top_coat 24\n",
      "ben_004::top_tshirt 24\n"
     ]
    }
   ],
   "source": [
    "out_dir = Path(\"/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/garment_dicts\")\n",
    "\n",
    "for k, v in garments_dict.items():\n",
    "    v['name'] = k\n",
    "\n",
    "    lbs_shape = v['lbs']['lbs_weights'].shape[-1]\n",
    "\n",
    "    bmodel = 'smpl' if lbs_shape == 24 else 'smplx'\n",
    "    out_path = out_dir / bmodel /  f\"{k}.pkl\"\n",
    "\n",
    "    print(k, lbs_shape)\n",
    "    pickle_dump(v, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference with individual garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOOD_PROJECT =  \"/local/home/agrigorev/Workdir/00_Projects/contourcraft_private\"\n",
    "HOOD_DATA = \"/local/home/agrigorev/Data/02_Projects/ccraft_data\"\n",
    "\n",
    "os.environ[\"HOOD_PROJECT\"] = HOOD_PROJECT\n",
    "os.environ[\"HOOD_DATA\"] = HOOD_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/utils/validation.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "from utils.validation import apply_material_params\n",
    "from utils.validation import load_runner_from_checkpoint\n",
    "from utils.arguments import load_params\n",
    "from utils.common import move2device\n",
    "from utils.io import pickle_dump\n",
    "from utils.defaults import DEFAULTS\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Set material paramenters, see configs/cvpr.yaml for the training ranges for each parameter\n",
    "material_dict = dict()\n",
    "material_dict['density'] = 0.20022\n",
    "material_dict['lame_mu'] = 23600.0\n",
    "material_dict['lame_lambda'] = 44400\n",
    "material_dict['bending_coeff'] = 3.962e-05\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "models_dir = Path(DEFAULTS.data_root) / 'trained_models'\n",
    "\n",
    "# Choose the model and the configuration file\n",
    "config_name = 'ccraft_indgd'\n",
    "checkpoint_path = models_dir / 'contourcraft.pth'\n",
    "\n",
    "checkpoint_path = '/local/home/agrigorev/Data/server4-data/experiments/wandb/run-20250219_193026-ibz41e57/checkpoints/step_0000036000.pth'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "# load the config from .yaml file and load .py modules specified there\n",
    "modules, experiment_config = load_params(config_name)\n",
    "\n",
    "# modify the config to use it in validation \n",
    "experiment_config = apply_material_params(experiment_config, material_dict)\n",
    "\n",
    "# load Runner object and the .py module it is declared in\n",
    "runner_module, runner = load_runner_from_checkpoint(checkpoint_path, modules, experiment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with the pose sequence\n",
    "from utils.validation import create_postcvpr_one_sequence_dataloader\n",
    "\n",
    "# If True, the SMPL(-X) poses are slightly modified to avoid hand-body self-penetrations. The technique is adopted from the code of SNUG \n",
    "separate_arms = True\n",
    "\n",
    "# path to the pose sequence file\n",
    "# sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smplx/CMU//01/01_01_stageii.npz'\n",
    "sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU//01/01_01_poses.npz'\n",
    "\n",
    "# name of the garment to simulate\n",
    "# garment_name = 'cindy_020_combined_test'\n",
    "garment_name = 'ben_004::top_coat,ben_004::scarf'\n",
    "\n",
    "# It can be a comma-separated list of individual garments\n",
    "# garment_name = 'cindy_020::bottom_skirt, cindy_020::top_blouse'\n",
    "\n",
    "garment_dict_file = 'garments_dict.pkl'\n",
    "\n",
    "\n",
    "# gender of the body model, sould be the same as the one used to create the garment\n",
    "# gender = 'female'\n",
    "gender = 'male'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "# Choose the type of the pose sequence you want to use: 'cmu_npz_smpl', 'cmu_npz_smplx', 'hood_pkl'\n",
    "\n",
    "# to use AMASS SMPL-X pose sequence\n",
    "# sequence_loader = 'cmu_npz_smplx'\n",
    "\n",
    "# to use AMASS SMPL pose sequence\n",
    "sequence_loader = 'cmu_npz_smpl'\n",
    "\n",
    "# to use our (legacy) SMPL pose sequence\n",
    "# sequence_loader = 'hood_pkl'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, \n",
    "                                            garment_dict_file, sequence_loader=sequence_loader, \n",
    "                                            obstacle_dict_file=None, config=\"ccraft_indgd\", gender=gender)\n",
    "# dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, \n",
    "#                                             garment_dict_file, sequence_loader=sequence_loader, \n",
    "#                                             obstacle_dict_file=None, config=\"ccraft_indgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module utils.warp_u.proximity b91666f load on device 'cuda:0' took 7.79 ms  (cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:07<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence = next(iter(dataloader))\n",
    "sequence = move2device(sequence, 'cuda:0')\n",
    "trajectories_dict = runner.valid_rollout(sequence,  bare=True, n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_dump\n",
    "\n",
    "out_path = '/local/home/agrigorev/Data/temp/out.pkl'\n",
    "pickle_dump(trajectories_dict, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check datalists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def proc_id(old_id):\n",
    "    parts = old_id.split('_')\n",
    "\n",
    "    person_id = parts[-2]\n",
    "    seq_id = parts[-1]\n",
    "\n",
    "    relative_path = f\"{person_id}/{person_id}_{seq_id}_poses.npz\"\n",
    "\n",
    "    return relative_path\n",
    "\n",
    "def get_lengths(amass_root, id_list):\n",
    "    ids_unique = list(set(id_list))\n",
    "    lengths = {}\n",
    "\n",
    "    for id in ids_unique:\n",
    "        path = f\"{amass_root}/{id}\"\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Path {id} does not exist\")\n",
    "            lengths[id] = -1\n",
    "            continue\n",
    "\n",
    "        data = dict(np.load(path, allow_pickle=True))\n",
    "        l = data['poses'].shape[0]\n",
    "        lengths[id] = l     \n",
    "\n",
    "    return lengths   \n",
    "\n",
    "datasplit_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "datasplit = pd.read_csv(datasplit_path)\n",
    "\n",
    "datasplit_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits_unique = list(set(datasplit['garment']))\n",
    "garments_unique = []\n",
    "for ou in outfits_unique:\n",
    "    garments_unique += ou.split(',')\n",
    "garments_unique = sorted(list(set(garments_unique)))\n",
    "\n",
    "def get_gender(garment):\n",
    "    gender = 'female'\n",
    "    for p in ['aaron', 'ben']:\n",
    "        if p in garment:\n",
    "            gender = 'male'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 104/104_04_poses.npz does not exist\n",
      "Path 26/26_11_poses.npz does not exist\n",
      "Path 104/104_53_poses.npz does not exist\n",
      "Path 104/104_17_poses.npz does not exist\n",
      "Path 104/104_11_poses.npz does not exist\n",
      "Path 144/144_30_poses.npz does not exist\n"
     ]
    }
   ],
   "source": [
    "ids_old = datasplit['id'].values\n",
    "ids_new = [proc_id(old_id) for old_id in ids_old]\n",
    "\n",
    "amass_root = '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU'\n",
    "length_dict = get_lengths(amass_root, ids_new)\n",
    "\n",
    "new_df_dict = defaultdict(list)\n",
    "\n",
    "for i, id in enumerate(ids_new):\n",
    "    l = length_dict[id]\n",
    "\n",
    "    if l > 0:\n",
    "        new_df_dict['id'].append(id)\n",
    "        new_df_dict['length'].append(length_dict[id])\n",
    "\n",
    "        garment = datasplit['garment'].values[i]\n",
    "        new_df_dict['garment'].append(garment)\n",
    "\n",
    "\n",
    "        gender = get_gender(garment)\n",
    "        new_df_dict['gender'].append(gender)\n",
    "\n",
    "datasplit_new = pd.DataFrame()\n",
    "\n",
    "for k, v in new_df_dict.items():\n",
    "    datasplit_new[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_new.to_csv('/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from utils.defaults import DEFAULTS\n",
    "\n",
    "from utils.arguments import load_params, create_modules\n",
    "\n",
    "s = 59\n",
    "torch.manual_seed(s)\n",
    "np.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/utils/arguments.py:261: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED CHECKPOINT FROM /local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/orig_pretrain.pth\n",
      "optimizer LOADED!\n",
      "scheduler LOADED!\n"
     ]
    }
   ],
   "source": [
    "# modules, config = load_params(config_name='ccraft_train_s1_debug')\n",
    "from utils.arguments import load_from_checkpoint\n",
    "\n",
    "\n",
    "modules, config = load_params(config_name='ccraft_train_s2_debug')\n",
    "dataloader_ms, runner_module, runner, aux_modules = create_modules(modules, config)\n",
    "\n",
    "checkpoint_path = Path(DEFAULTS.data_root) / 'trained_models' / 'contourcraft.pth'\n",
    "\n",
    "#restangles\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/server4-data/experiments/wandb/run-20250219_193026-ibz41e57/checkpoints/step_0000050000.pth'\n",
    "\n",
    "# regular\n",
    "# checkpoint_path = '/local/home/agrigorev/Data/server4-data/experiments/wandb/run-20250220_142545-274x63w1/checkpoints/step_0000050000.pth'\n",
    "\n",
    "checkpoint_path = 'trained_models/orig_pretrain.pth'\n",
    "config.restart.checkpoint_path = checkpoint_path\n",
    "\n",
    "# if config.experiment.checkpoint_path is not None and os.path.exists(config.experiment.checkpoint_path):\n",
    "#     sd = torch.load(config.experiment.checkpoint_path)\n",
    "\n",
    "#     if 'training_module' in sd:\n",
    "#         runner.load_state_dict(sd['training_module'])\n",
    "\n",
    "#         for k, v in aux_modules.items():\n",
    "#             if k in sd:\n",
    "#                 print(f'{k} LOADED!')\n",
    "#                 v.load_state_dict(sd[k])\n",
    "#     else:\n",
    "#         runner.load_state_dict(sd)\n",
    "#     print('LOADED:', config.experiment.checkpoint_path)\n",
    "\n",
    "runner, aux_modules = load_from_checkpoint(config, runner, aux_modules)\n",
    "dataloaders_dict = dict()\n",
    "for dataloader_name, dataloader in dataloader_ms.items():\n",
    "    dataloaders_dict[dataloader_name] = dataloader.create_dataloader()\n",
    "\n",
    "dataloader_short = dataloaders_dict['short']\n",
    "dataloader_long = dataloaders_dict['long']\n",
    "\n",
    "sample_short = next(iter(dataloader_short))\n",
    "sample_long = next(iter(dataloader_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s2_debug:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garment name ben_004::top_coat,ben_004::scarf\n",
      "sequence_name 144/144_26_poses.npz\n",
      "roll_steps 100\n",
      "loss tensor(32323.5664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(29465.5098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(27091.5039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(22646.0078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(20852.5176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(19912.2266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(18403.6445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(16512.9219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(15631.7949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(13511.7754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(11236.4678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(10401.1152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss tensor(10531.0352, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s2_debug:   0%|          | 0/2 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m global_step \u001b[38;5;241m=\u001b[39m \u001b[43mrunner_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_modules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:854\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(runner, aux_modules, dataloaders_dict, cfg, writer, global_step)\u001b[0m\n\u001b[1;32m    852\u001b[0m     ld_to_write \u001b[38;5;241m=\u001b[39m step_short(runner, global_step, sample, optimizer, scheduler)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m curr_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 854\u001b[0m     ld_to_write \u001b[38;5;241m=\u001b[39m \u001b[43mstep_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWrong step label \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:766\u001b[0m, in \u001b[0;36mstep_long\u001b[0;34m(runner, sample, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_long\u001b[39m(runner, sample, optimizer, scheduler):\n\u001b[0;32m--> 766\u001b[0m     ld_to_write \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ld_to_write\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:677\u001b[0m, in \u001b[0;36mRunner.forward_long\u001b[0;34m(self, sample, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    672\u001b[0m     metrics_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mncoll\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ncoll)\n\u001b[1;32m    676\u001b[0m loss_dict_impulse, loss_weight_dict_impulse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_dict_hood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m prev_out_sample \u001b[38;5;241m=\u001b[39m sample_step\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_safecheck \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last_step:\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:413\u001b[0m, in \u001b[0;36mRunner.optimizer_step\u001b[0;34m(self, optimizer, scheduler, loss_dict, gradient_dict, sample_step)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gradient_name, gradient \u001b[38;5;129;01min\u001b[39;00m gradient_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# print(gradient_name, gradient.abs().sum())\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gradient(sample_step, optimizer, gradient, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m)\n\u001b[0;32m--> 413\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcfg\u001b[38;5;241m.\u001b[39mgrad_clip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcfg\u001b[38;5;241m.\u001b[39mgrad_clip)\n",
      "File \u001b[0;32m~/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "global_step = runner_module.run_epoch(runner, aux_modules, dataloaders_dict, config, None,\n",
    "                                global_step=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load\n",
    "\n",
    "seq_id = 'long_50001'\n",
    "traj_path_new = f'/local/home/agrigorev/Data/temp/debug/{seq_id}.pkl'\n",
    "# traj_path_old = f'/local/home/agrigorev/Data/temp/debug_old/{seq_id}.pkl'\n",
    "traj_path_old = f'/local/home/agrigorev/Data/temp/debug_old/long_50005.pkl'\n",
    "\n",
    "traj_new = pickle_load(traj_path_new)\n",
    "traj_old = pickle_load(traj_path_old)\n",
    "\n",
    "traj_old['metrics'] = {k[5:]: v for k, v in traj_old['metrics'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impulse_iters 3.3535353535353534 0.5757575757575758\n",
      "impulse_stencil_ncoll 18.09090909090909 4.848484848484849\n",
      "riz_iters 0.030303030303030304 0.0\n",
      "riz_itersmax_riz_size 14 0\n",
      "hood/stretching_energy_loss 0.46309065982699393 0.3990580676496029\n",
      "hood/bending_energy_loss 0.05469794849625032 0.05483933967601842\n",
      "hood/inertia_loss 0.005737926782021532 0.005145852939167525\n",
      "hood/gravitational_energy_loss 5.911851909756661 0.24605285611003638\n",
      "hood/collision_penalty_loss 1.5756199880712665e-06 3.8512562416271974e-08\n",
      "hood/repulsion_loss 0.0010708723684215546 0.00103699604091683\n"
     ]
    }
   ],
   "source": [
    "for k in traj_new['metrics'].keys():\n",
    "    if k in traj_old['metrics']:\n",
    "        print(k, traj_new['metrics'][k], traj_old['metrics'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hood/stretching_energy_loss': 0.3489467564970255,\n",
       " 'hood/bending_energy_loss': 0.052061445642502806,\n",
       " 'hood/inertia_loss': 0.005703017642517807,\n",
       " 'hood/gravitational_energy_loss': 5.70411994278431,\n",
       " 'hood/collision_penalty_loss': 1.7778491685324115e-06,\n",
       " 'hood/repulsion_loss': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_new['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long/hood/stretching_energy_loss': 0.3008002529293299,\n",
       " 'long/hood/inertia_loss': 0.005532875381904887,\n",
       " 'long/hood/gravitational_energy_loss': 0.18318553576245905,\n",
       " 'long/hood/bending_energy_loss': 0.06113392335770186,\n",
       " 'long/hood/collision_penalty_loss': 3.893926055232442e-08,\n",
       " 'long/hood/repulsion_loss': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_old['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make debug datalists for new and old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "old_datasplit = pd.read_csv(old_df_path)\n",
    "\n",
    "\n",
    "new_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv'\n",
    "new_datasplit = pd.read_csv(new_df_path)\n",
    "new_row = new_datasplit.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2730"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(old_datasplit.length.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_datasplit_f1 = old_datasplit[old_datasplit.garment=='ben_004::top_coat,ben_004::scarf']\n",
    "old_row = old_datasplit_f1.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>garment</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29171</th>\n",
       "      <td>32707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape14_144_26</td>\n",
       "      <td>1480</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0                     id  length  \\\n",
       "29171         32707         NaN  tshirt_shape14_144_26    1480   \n",
       "\n",
       "                                garment gender  \n",
       "29171  ben_004::top_coat,ben_004::scarf   male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row.to_csv('/local/home/agrigorev/Data/temp/datasplits/new.csv', index=False)\n",
    "old_row.to_csv('/local/home/agrigorev/Data/temp/datasplits/old.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "a = Batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.short_is_training = True\n",
    "self.mcfg.long_is_training = True\n",
    "self.mcfg.nocollect_after = 2\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "\n",
    "```\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.nocollect_after = 2\n",
    "self.mcfg.short_is_training = True\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

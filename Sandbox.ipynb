{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load, pickle_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "garment_dict_path = '/local/home/agrigorev/Data/02_Projects/hood_data/aux_data/garments_dict.pkl'\n",
    "garment_dict_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/train_wdetailed2.pkl'\n",
    "\n",
    "garments_dict = pickle_load(garment_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/garment_dicts\"\n",
    "\n",
    "for k, v in garments_dict.items():\n",
    "    v['name'] = k\n",
    "    pickle_dump(v, f\"{out_dir}/{k}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference with individual garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOOD_PROJECT =  \"/local/home/agrigorev/Workdir/00_Projects/contourcraft_private\"\n",
    "HOOD_DATA = \"/local/home/agrigorev/Data/02_Projects/ccraft_data\"\n",
    "\n",
    "os.environ[\"HOOD_PROJECT\"] = HOOD_PROJECT\n",
    "os.environ[\"HOOD_DATA\"] = HOOD_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/utils/validation.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "from utils.validation import apply_material_params\n",
    "from utils.validation import load_runner_from_checkpoint\n",
    "from utils.arguments import load_params\n",
    "from utils.common import move2device\n",
    "from utils.io import pickle_dump\n",
    "from utils.defaults import DEFAULTS\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Set material paramenters, see configs/cvpr.yaml for the training ranges for each parameter\n",
    "material_dict = dict()\n",
    "material_dict['density'] = 0.20022\n",
    "material_dict['lame_mu'] = 23600.0\n",
    "material_dict['lame_lambda'] = 44400\n",
    "material_dict['bending_coeff'] = 3.962e-05\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "models_dir = Path(DEFAULTS.data_root) / 'trained_models'\n",
    "\n",
    "# Choose the model and the configuration file\n",
    "config_name = 'ccraft_indgd'\n",
    "checkpoint_path = models_dir / 'contourcraft.pth'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "# load the config from .yaml file and load .py modules specified there\n",
    "modules, experiment_config = load_params(config_name)\n",
    "\n",
    "# modify the config to use it in validation \n",
    "experiment_config = apply_material_params(experiment_config, material_dict)\n",
    "\n",
    "# load Runner object and the .py module it is declared in\n",
    "runner_module, runner = load_runner_from_checkpoint(checkpoint_path, modules, experiment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU//01', 'single_sequence_file': '01_01_poses', 'single_sequence_garment': 'ben_004::top_coat,ben_004::scarf', 'sequence_loader': 'cmu_npz_smpl', 'obstacle_dict_file': None, 'gender': 'male'}\n"
     ]
    }
   ],
   "source": [
    "# file with the pose sequence\n",
    "from utils.validation import create_postcvpr_one_sequence_dataloader\n",
    "\n",
    "# If True, the SMPL(-X) poses are slightly modified to avoid hand-body self-penetrations. The technique is adopted from the code of SNUG \n",
    "separate_arms = True\n",
    "\n",
    "# path to the pose sequence file\n",
    "# sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smplx/CMU//01/01_01_stageii.npz'\n",
    "sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU//01/01_01_poses.npz'\n",
    "\n",
    "# name of the garment to simulate\n",
    "# garment_name = 'cindy_020_combined_test'\n",
    "garment_name = 'ben_004::top_coat,ben_004::scarf'\n",
    "\n",
    "# It can be a comma-separated list of individual garments\n",
    "# garment_name = 'cindy_020::bottom_skirt, cindy_020::top_blouse'\n",
    "\n",
    "garment_dict_file = 'garments_dict.pkl'\n",
    "\n",
    "\n",
    "# gender of the body model, sould be the same as the one used to create the garment\n",
    "# gender = 'female'\n",
    "gender = 'male'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "# Choose the type of the pose sequence you want to use: 'cmu_npz_smpl', 'cmu_npz_smplx', 'hood_pkl'\n",
    "\n",
    "# to use AMASS SMPL-X pose sequence\n",
    "# sequence_loader = 'cmu_npz_smplx'\n",
    "\n",
    "# to use AMASS SMPL pose sequence\n",
    "sequence_loader = 'cmu_npz_smpl'\n",
    "\n",
    "# to use our (legacy) SMPL pose sequence\n",
    "# sequence_loader = 'hood_pkl'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, \n",
    "                                            garment_dict_file, sequence_loader=sequence_loader, \n",
    "                                            obstacle_dict_file=None, config=\"ccraft_indgd\", gender=gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence = next(iter(dataloader))\n",
    "sequence = move2device(sequence, 'cuda:0')\n",
    "trajectories_dict = runner.valid_rollout(sequence,  bare=True, n_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_dump\n",
    "\n",
    "out_path = '/local/home/agrigorev/Data/temp/out.pkl'\n",
    "pickle_dump(trajectories_dict, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check datalists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def proc_id(old_id):\n",
    "    parts = old_id.split('_')\n",
    "\n",
    "    person_id = parts[-2]\n",
    "    seq_id = parts[-1]\n",
    "\n",
    "    relative_path = f\"{person_id}/{person_id}_{seq_id}_poses.npz\"\n",
    "\n",
    "    return relative_path\n",
    "\n",
    "def get_lengths(amass_root, id_list):\n",
    "    ids_unique = list(set(id_list))\n",
    "    lengths = {}\n",
    "\n",
    "    for id in ids_unique:\n",
    "        path = f\"{amass_root}/{id}\"\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Path {id} does not exist\")\n",
    "            lengths[id] = -1\n",
    "            continue\n",
    "\n",
    "        data = dict(np.load(path, allow_pickle=True))\n",
    "        l = data['poses'].shape[0]\n",
    "        lengths[id] = l     \n",
    "\n",
    "    return lengths   \n",
    "\n",
    "datasplit_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "datasplit = pd.read_csv(datasplit_path)\n",
    "\n",
    "datasplit_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits_unique = list(set(datasplit['garment']))\n",
    "garments_unique = []\n",
    "for ou in outfits_unique:\n",
    "    garments_unique += ou.split(',')\n",
    "garments_unique = sorted(list(set(garments_unique)))\n",
    "\n",
    "def get_gender(garment):\n",
    "    gender = 'female'\n",
    "    for p in ['aaron', 'ben']:\n",
    "        if p in garment:\n",
    "            gender = 'male'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 104/104_04_poses.npz does not exist\n",
      "Path 26/26_11_poses.npz does not exist\n",
      "Path 104/104_53_poses.npz does not exist\n",
      "Path 104/104_17_poses.npz does not exist\n",
      "Path 104/104_11_poses.npz does not exist\n",
      "Path 144/144_30_poses.npz does not exist\n"
     ]
    }
   ],
   "source": [
    "ids_old = datasplit['id'].values\n",
    "ids_new = [proc_id(old_id) for old_id in ids_old]\n",
    "\n",
    "amass_root = '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU'\n",
    "length_dict = get_lengths(amass_root, ids_new)\n",
    "\n",
    "new_df_dict = defaultdict(list)\n",
    "\n",
    "for i, id in enumerate(ids_new):\n",
    "    l = length_dict[id]\n",
    "\n",
    "    if l > 0:\n",
    "        new_df_dict['id'].append(id)\n",
    "        new_df_dict['length'].append(length_dict[id])\n",
    "\n",
    "        garment = datasplit['garment'].values[i]\n",
    "        new_df_dict['garment'].append(garment)\n",
    "\n",
    "\n",
    "        gender = get_gender(garment)\n",
    "        new_df_dict['gender'].append(gender)\n",
    "\n",
    "datasplit_new = pd.DataFrame()\n",
    "\n",
    "for k, v in new_df_dict.items():\n",
    "    datasplit_new[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_new.to_csv('/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from utils.defaults import DEFAULTS\n",
    "\n",
    "from utils.arguments import load_params, create_modules\n",
    "\n",
    "s = 59\n",
    "torch.manual_seed(s)\n",
    "np.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_541424/1370080531.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(config.experiment.checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer LOADED!\n",
      "scheduler LOADED!\n",
      "LOADED: /local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/contourcraft.pth\n",
      "garment_name beatrice_019::bottom,beatrice_019::top_shirt\n",
      "gender female\n",
      "garment_name aaron_009::top\n",
      "gender male\n"
     ]
    }
   ],
   "source": [
    "modules, config = load_params(config_name='ccraft_train_s1_debug')\n",
    "dataloader_ms, runner_module, runner, aux_modules = create_modules(modules, config)\n",
    "\n",
    "checkpoint_path = Path(DEFAULTS.data_root) / 'trained_models' / 'contourcraft.pth'\n",
    "config.experiment.checkpoint_path = checkpoint_path\n",
    "\n",
    "if config.experiment.checkpoint_path is not None and os.path.exists(config.experiment.checkpoint_path):\n",
    "    sd = torch.load(config.experiment.checkpoint_path)\n",
    "\n",
    "    if 'training_module' in sd:\n",
    "        runner.load_state_dict(sd['training_module'])\n",
    "\n",
    "        for k, v in aux_modules.items():\n",
    "            if k in sd:\n",
    "                print(f'{k} LOADED!')\n",
    "                v.load_state_dict(sd[k])\n",
    "    else:\n",
    "        runner.load_state_dict(sd)\n",
    "    print('LOADED:', config.experiment.checkpoint_path)\n",
    "\n",
    "\n",
    "dataloaders_dict = dict()\n",
    "for dataloader_name, dataloader in dataloader_ms.items():\n",
    "    dataloaders_dict[dataloader_name] = dataloader.create_dataloader()\n",
    "\n",
    "dataloader_short = dataloaders_dict['short']\n",
    "dataloader_long = dataloaders_dict['long']\n",
    "\n",
    "sample_short = next(iter(dataloader_short))\n",
    "sample_long = next(iter(dataloader_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 0/51612 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garment_name aaron_013::top,aaron_013::bottom\n",
      "gender male\n",
      "garment name aaron_013::top,aaron_013::bottom\n",
      "sequence_name 128/128_02_poses.npz\n",
      "roll_steps 40\n",
      "Module utils.warp_u.proximity b91666f load on device 'cuda:0' took 0.75 ms  (cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 1/51612 [00:17<256:09:18, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long saved to /local/home/agrigorev/Data/temp/debug/long_50001.pkl\n",
      "garment_name pants\n",
      "gender female\n",
      "garment name pants\n",
      "sequence_name 40/40_12_poses.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 2/51612 [00:22<141:59:36,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short saved to /local/home/agrigorev/Data/temp/debug/short_50002.pkl\n",
      "garment_name dress\n",
      "gender female\n",
      "garment name dress\n",
      "sequence_name 128/128_06_poses.npz\n",
      "roll_steps 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/runners/utils/impulses.py:61: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647382455/work/aten/src/ATen/native/Cross.cpp:62.)\n",
      "  angular_momentum = torch.cross(mass_weighted_velocities, positions_relative_to_com).sum(dim=0)\n",
      "ccraft_train_s1_debug:   0%|          | 3/51612 [01:00<326:40:05, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long saved to /local/home/agrigorev/Data/temp/debug/long_50003.pkl\n",
      "garment_name tshirt_unzipped\n",
      "gender female\n",
      "garment name tshirt_unzipped\n",
      "sequence_name 91/91_61_poses.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 4/51612 [01:02<211:55:44, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short saved to /local/home/agrigorev/Data/temp/debug/short_50004.pkl\n",
      "garment_name beatrice_019::bottom\n",
      "gender female\n",
      "garment name beatrice_019::bottom\n",
      "sequence_name 128/128_06_poses.npz\n",
      "roll_steps 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 5/51612 [01:18<217:10:52, 15.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long saved to /local/home/agrigorev/Data/temp/debug/long_50005.pkl\n",
      "garment_name dress\n",
      "gender female\n",
      "garment name dress\n",
      "sequence_name 111/111_14_poses.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 6/51612 [01:27<188:07:30, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short saved to /local/home/agrigorev/Data/temp/debug/short_50006.pkl\n",
      "garment_name beatrice_019::bottom,beatrice_019::top_apron\n",
      "gender female\n",
      "garment name beatrice_019::bottom,beatrice_019::top_apron\n",
      "sequence_name 135/135_07_poses.npz\n",
      "roll_steps 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 6/51612 [01:29<214:06:47, 14.94s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 11.65 GiB of which 168.62 MiB is free. Including non-PyTorch memory, this process has 9.19 GiB memory in use. Of the allocated memory 8.49 GiB is allocated by PyTorch, and 510.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m global_step \u001b[38;5;241m=\u001b[39m \u001b[43mrunner_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_modules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:852\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(runner, aux_modules, dataloaders_dict, cfg, writer, global_step)\u001b[0m\n\u001b[1;32m    850\u001b[0m     ld_to_write \u001b[38;5;241m=\u001b[39m step_short(runner, global_step, sample, optimizer, scheduler)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m curr_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 852\u001b[0m     ld_to_write \u001b[38;5;241m=\u001b[39m \u001b[43mstep_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWrong step label \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:764\u001b[0m, in \u001b[0;36mstep_long\u001b[0;34m(runner, sample, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep_long\u001b[39m(runner, sample, optimizer, scheduler):\n\u001b[0;32m--> 764\u001b[0m     ld_to_write \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_long\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ld_to_write\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/ccraft_debug.py:671\u001b[0m, in \u001b[0;36mRunner.forward_long\u001b[0;34m(self, sample, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    667\u001b[0m loss_dict_hood, loss_weight_dict_hood, gradient_dict, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_pass(sample_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_dict_hood)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_wedges_seq:\n\u001b[0;32m--> 671\u001b[0m     ncoll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafecheck_solver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_tritri_collisions2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m     metrics_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mncoll\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ncoll)\n\u001b[1;32m    676\u001b[0m loss_dict_impulse, loss_weight_dict_impulse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/runners/utils/impulses.py:868\u001b[0m, in \u001b[0;36mCollisionSolver.calc_tritri_collisions2\u001b[0;34m(sample, obj_key, verts_key, threshold)\u001b[0m\n\u001b[1;32m    865\u001b[0m faces \u001b[38;5;241m=\u001b[39m sample[obj_key]\u001b[38;5;241m.\u001b[39mfaces_batch\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    866\u001b[0m pos \u001b[38;5;241m=\u001b[39m pos\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[0;32m--> 868\u001b[0m collisions_tri \u001b[38;5;241m=\u001b[39m \u001b[43mfind_close_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenetrating_mask\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sample[obj_key]:\n\u001b[1;32m    871\u001b[0m     penetrating_mask \u001b[38;5;241m=\u001b[39m sample[obj_key]\u001b[38;5;241m.\u001b[39mpenetrating_mask\n",
      "File \u001b[0;32m~/Workdir/00_Projects/contourcraft_private/utils/selfcollisions.py:57\u001b[0m, in \u001b[0;36mfind_close_faces\u001b[0;34m(vertices, faces, threshold)\u001b[0m\n\u001b[1;32m     55\u001b[0m triangles \u001b[38;5;241m=\u001b[39m vertices[faces]\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     56\u001b[0m bboxes, tree \u001b[38;5;241m=\u001b[39m collisions\u001b[38;5;241m.\u001b[39mbvh(triangles)\n\u001b[0;32m---> 57\u001b[0m face_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mcollisions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_collisions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriangles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     58\u001b[0m face_pairs \u001b[38;5;241m=\u001b[39m face_pairs[face_pairs[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m face_pairs\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 11.65 GiB of which 168.62 MiB is free. Including non-PyTorch memory, this process has 9.19 GiB memory in use. Of the allocated memory 8.49 GiB is allocated by PyTorch, and 510.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "global_step = runner_module.run_epoch(runner, aux_modules, dataloaders_dict, config, None,\n",
    "                                global_step=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make debug datalists for new and old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "old_datasplit = pd.read_csv(old_df_path)\n",
    "old_datasplit_id = \n",
    "\n",
    "\n",
    "new_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv'\n",
    "new_datasplit = pd.read_csv(new_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>garment</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tshirt_shape14_104_11</td>\n",
       "      <td>1320</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tshirt_shape08_128_02</td>\n",
       "      <td>390</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tshirt_shape14_128_03</td>\n",
       "      <td>390</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>tshirt_shape03_91_61</td>\n",
       "      <td>880</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>tshirt_shape10_46_01</td>\n",
       "      <td>1520</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29167</th>\n",
       "      <td>32703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape09_144_26</td>\n",
       "      <td>1480</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29168</th>\n",
       "      <td>32704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape04_91_38</td>\n",
       "      <td>1120</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29169</th>\n",
       "      <td>32705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape16_104_11</td>\n",
       "      <td>1320</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29170</th>\n",
       "      <td>32706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape03_111_37</td>\n",
       "      <td>790</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29171</th>\n",
       "      <td>32707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape14_144_26</td>\n",
       "      <td>1480</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29172 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0                     id  length  \\\n",
       "0                 0         0.0  tshirt_shape14_104_11    1320   \n",
       "1                 1         1.0  tshirt_shape08_128_02     390   \n",
       "2                 2         2.0  tshirt_shape14_128_03     390   \n",
       "3                 3         3.0   tshirt_shape03_91_61     880   \n",
       "4                 4         4.0   tshirt_shape10_46_01    1520   \n",
       "...             ...         ...                    ...     ...   \n",
       "29167         32703         NaN  tshirt_shape09_144_26    1480   \n",
       "29168         32704         NaN   tshirt_shape04_91_38    1120   \n",
       "29169         32705         NaN  tshirt_shape16_104_11    1320   \n",
       "29170         32706         NaN  tshirt_shape03_111_37     790   \n",
       "29171         32707         NaN  tshirt_shape14_144_26    1480   \n",
       "\n",
       "                                garment  gender  \n",
       "0                                tshirt  female  \n",
       "1                                tshirt  female  \n",
       "2                                tshirt  female  \n",
       "3                                tshirt  female  \n",
       "4                                tshirt  female  \n",
       "...                                 ...     ...  \n",
       "29167  ben_004::top_coat,ben_004::scarf    male  \n",
       "29168  ben_004::top_coat,ben_004::scarf    male  \n",
       "29169  ben_004::top_coat,ben_004::scarf    male  \n",
       "29170  ben_004::top_coat,ben_004::scarf    male  \n",
       "29171  ben_004::top_coat,ben_004::scarf    male  \n",
       "\n",
       "[29172 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>garment</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91/91_61_poses.npz</td>\n",
       "      <td>362</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46/46_01_poses.npz</td>\n",
       "      <td>616</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111/111_37_poses.npz</td>\n",
       "      <td>324</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108/108_12_poses.npz</td>\n",
       "      <td>137</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144/144_28_poses.npz</td>\n",
       "      <td>2286</td>\n",
       "      <td>tshirt</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20752</th>\n",
       "      <td>111/111_05_poses.npz</td>\n",
       "      <td>926</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20753</th>\n",
       "      <td>144/144_26_poses.npz</td>\n",
       "      <td>3347</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20754</th>\n",
       "      <td>91/91_38_poses.npz</td>\n",
       "      <td>458</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20755</th>\n",
       "      <td>111/111_37_poses.npz</td>\n",
       "      <td>324</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20756</th>\n",
       "      <td>144/144_26_poses.npz</td>\n",
       "      <td>3347</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  length                           garment  gender\n",
       "0        91/91_61_poses.npz     362                            tshirt  female\n",
       "1        46/46_01_poses.npz     616                            tshirt  female\n",
       "2      111/111_37_poses.npz     324                            tshirt  female\n",
       "3      108/108_12_poses.npz     137                            tshirt  female\n",
       "4      144/144_28_poses.npz    2286                            tshirt  female\n",
       "...                     ...     ...                               ...     ...\n",
       "20752  111/111_05_poses.npz     926  ben_004::top_coat,ben_004::scarf    male\n",
       "20753  144/144_26_poses.npz    3347  ben_004::top_coat,ben_004::scarf    male\n",
       "20754    91/91_38_poses.npz     458  ben_004::top_coat,ben_004::scarf    male\n",
       "20755  111/111_37_poses.npz     324  ben_004::top_coat,ben_004::scarf    male\n",
       "20756  144/144_26_poses.npz    3347  ben_004::top_coat,ben_004::scarf    male\n",
       "\n",
       "[20757 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "a = Batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.short_is_training = True\n",
    "self.mcfg.long_is_training = True\n",
    "self.mcfg.nocollect_after = 2\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "\n",
    "```\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.nocollect_after = 2\n",
    "self.mcfg.short_is_training = True\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

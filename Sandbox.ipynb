{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load, pickle_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b8dbabb7f70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "garment_dict_path = '/local/home/agrigorev/Data/02_Projects/hood_data/aux_data/garments_dict.pkl'\n",
    "garment_dict_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/train_wdetailed2.pkl'\n",
    "\n",
    "garments_dict = pickle_load(garment_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/garment_dicts\"\n",
    "\n",
    "for k, v in garments_dict.items():\n",
    "    v['name'] = k\n",
    "    pickle_dump(v, f\"{out_dir}/{k}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test inference with individual garment dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOOD_PROJECT =  \"/local/home/agrigorev/Workdir/00_Projects/contourcraft_private\"\n",
    "HOOD_DATA = \"/local/home/agrigorev/Data/02_Projects/ccraft_data\"\n",
    "\n",
    "os.environ[\"HOOD_PROJECT\"] = HOOD_PROJECT\n",
    "os.environ[\"HOOD_DATA\"] = HOOD_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/Workdir/00_Projects/contourcraft_private/utils/validation.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(checkpoint_path)\n"
     ]
    }
   ],
   "source": [
    "from utils.validation import apply_material_params\n",
    "from utils.validation import load_runner_from_checkpoint\n",
    "from utils.arguments import load_params\n",
    "from utils.common import move2device\n",
    "from utils.io import pickle_dump\n",
    "from utils.defaults import DEFAULTS\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Set material paramenters, see configs/cvpr.yaml for the training ranges for each parameter\n",
    "material_dict = dict()\n",
    "material_dict['density'] = 0.20022\n",
    "material_dict['lame_mu'] = 23600.0\n",
    "material_dict['lame_lambda'] = 44400\n",
    "material_dict['bending_coeff'] = 3.962e-05\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "models_dir = Path(DEFAULTS.data_root) / 'trained_models'\n",
    "\n",
    "# Choose the model and the configuration file\n",
    "config_name = 'ccraft_indgd'\n",
    "checkpoint_path = models_dir / 'contourcraft.pth'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "# load the config from .yaml file and load .py modules specified there\n",
    "modules, experiment_config = load_params(config_name)\n",
    "\n",
    "# modify the config to use it in validation \n",
    "experiment_config = apply_material_params(experiment_config, material_dict)\n",
    "\n",
    "# load Runner object and the .py module it is declared in\n",
    "runner_module, runner = load_runner_from_checkpoint(checkpoint_path, modules, experiment_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU//01', 'single_sequence_file': '01_01_poses', 'single_sequence_garment': 'ben_004::top_coat,ben_004::scarf', 'sequence_loader': 'cmu_npz_smpl', 'obstacle_dict_file': None, 'gender': 'male'}\n"
     ]
    }
   ],
   "source": [
    "# file with the pose sequence\n",
    "from utils.validation import create_postcvpr_one_sequence_dataloader\n",
    "\n",
    "# If True, the SMPL(-X) poses are slightly modified to avoid hand-body self-penetrations. The technique is adopted from the code of SNUG \n",
    "separate_arms = True\n",
    "\n",
    "# path to the pose sequence file\n",
    "# sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smplx/CMU//01/01_01_stageii.npz'\n",
    "sequence_path =  '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU//01/01_01_poses.npz'\n",
    "\n",
    "# name of the garment to simulate\n",
    "# garment_name = 'cindy_020_combined_test'\n",
    "garment_name = 'ben_004::top_coat,ben_004::scarf'\n",
    "\n",
    "# It can be a comma-separated list of individual garments\n",
    "# garment_name = 'cindy_020::bottom_skirt, cindy_020::top_blouse'\n",
    "\n",
    "garment_dict_file = 'garments_dict.pkl'\n",
    "\n",
    "\n",
    "# gender of the body model, sould be the same as the one used to create the garment\n",
    "# gender = 'female'\n",
    "gender = 'male'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "# Choose the type of the pose sequence you want to use: 'cmu_npz_smpl', 'cmu_npz_smplx', 'hood_pkl'\n",
    "\n",
    "# to use AMASS SMPL-X pose sequence\n",
    "# sequence_loader = 'cmu_npz_smplx'\n",
    "\n",
    "# to use AMASS SMPL pose sequence\n",
    "sequence_loader = 'cmu_npz_smpl'\n",
    "\n",
    "# to use our (legacy) SMPL pose sequence\n",
    "# sequence_loader = 'hood_pkl'\n",
    "\n",
    "\n",
    "# ====================================================================================================\n",
    "\n",
    "\n",
    "dataloader = create_postcvpr_one_sequence_dataloader(sequence_path, garment_name, \n",
    "                                            garment_dict_file, sequence_loader=sequence_loader, \n",
    "                                            obstacle_dict_file=None, config=\"ccraft_indgd\", gender=gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence = next(iter(dataloader))\n",
    "sequence = move2device(sequence, 'cuda:0')\n",
    "trajectories_dict = runner.valid_rollout(sequence,  bare=True, n_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_dump\n",
    "\n",
    "out_path = '/local/home/agrigorev/Data/temp/out.pkl'\n",
    "pickle_dump(trajectories_dict, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check datalists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def proc_id(old_id):\n",
    "    parts = old_id.split('_')\n",
    "\n",
    "    person_id = parts[-2]\n",
    "    seq_id = parts[-1]\n",
    "\n",
    "    relative_path = f\"{person_id}/{person_id}_{seq_id}_poses.npz\"\n",
    "\n",
    "    return relative_path\n",
    "\n",
    "def get_lengths(amass_root, id_list):\n",
    "    ids_unique = list(set(id_list))\n",
    "    lengths = {}\n",
    "\n",
    "    for id in ids_unique:\n",
    "        path = f\"{amass_root}/{id}\"\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Path {id} does not exist\")\n",
    "            lengths[id] = -1\n",
    "            continue\n",
    "\n",
    "        data = dict(np.load(path, allow_pickle=True))\n",
    "        l = data['poses'].shape[0]\n",
    "        lengths[id] = l     \n",
    "\n",
    "    return lengths   \n",
    "\n",
    "datasplit_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "datasplit = pd.read_csv(datasplit_path)\n",
    "\n",
    "datasplit_new = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits_unique = list(set(datasplit['garment']))\n",
    "garments_unique = []\n",
    "for ou in outfits_unique:\n",
    "    garments_unique += ou.split(',')\n",
    "garments_unique = sorted(list(set(garments_unique)))\n",
    "\n",
    "def get_gender(garment):\n",
    "    gender = 'female'\n",
    "    for p in ['aaron', 'ben']:\n",
    "        if p in garment:\n",
    "            gender = 'male'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 104/104_04_poses.npz does not exist\n",
      "Path 26/26_11_poses.npz does not exist\n",
      "Path 104/104_53_poses.npz does not exist\n",
      "Path 104/104_17_poses.npz does not exist\n",
      "Path 104/104_11_poses.npz does not exist\n",
      "Path 144/144_30_poses.npz does not exist\n"
     ]
    }
   ],
   "source": [
    "ids_old = datasplit['id'].values\n",
    "ids_new = [proc_id(old_id) for old_id in ids_old]\n",
    "\n",
    "amass_root = '/local/home/agrigorev/Data/00_Datasets/AMASS/smpl/CMU'\n",
    "length_dict = get_lengths(amass_root, ids_new)\n",
    "\n",
    "new_df_dict = defaultdict(list)\n",
    "\n",
    "for i, id in enumerate(ids_new):\n",
    "    l = length_dict[id]\n",
    "\n",
    "    if l > 0:\n",
    "        new_df_dict['id'].append(id)\n",
    "        new_df_dict['length'].append(length_dict[id])\n",
    "\n",
    "        garment = datasplit['garment'].values[i]\n",
    "        new_df_dict['garment'].append(garment)\n",
    "\n",
    "\n",
    "        gender = get_gender(garment)\n",
    "        new_df_dict['gender'].append(gender)\n",
    "\n",
    "datasplit_new = pd.DataFrame()\n",
    "\n",
    "for k, v in new_df_dict.items():\n",
    "    datasplit_new[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_new.to_csv('/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from utils.defaults import DEFAULTS\n",
    "\n",
    "from utils.arguments import load_params, create_modules\n",
    "\n",
    "s = 59\n",
    "torch.manual_seed(s)\n",
    "np.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/contourcraft.pth')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = Path(DEFAULTS.data_root) / 'trained_models' / 'contourcraft.pth'\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.5.1 initialized:\n",
      "   CUDA Toolkit 12.6, Driver 12.7\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3060\" (12 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /local/home/agrigorev/.cache/warp/1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_591221/1370080531.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(config.experiment.checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer LOADED!\n",
      "scheduler LOADED!\n",
      "LOADED: /local/home/agrigorev/Data/02_Projects/ccraft_data/trained_models/contourcraft.pth\n"
     ]
    }
   ],
   "source": [
    "modules, config = load_params(config_name='ccraft_train_s1_debug')\n",
    "dataloader_ms, runner_module, runner, aux_modules = create_modules(modules, config)\n",
    "\n",
    "checkpoint_path = Path(DEFAULTS.data_root) / 'trained_models' / 'contourcraft.pth'\n",
    "config.experiment.checkpoint_path = checkpoint_path\n",
    "\n",
    "if config.experiment.checkpoint_path is not None and os.path.exists(config.experiment.checkpoint_path):\n",
    "    sd = torch.load(config.experiment.checkpoint_path)\n",
    "\n",
    "    if 'training_module' in sd:\n",
    "        runner.load_state_dict(sd['training_module'])\n",
    "\n",
    "        for k, v in aux_modules.items():\n",
    "            if k in sd:\n",
    "                print(f'{k} LOADED!')\n",
    "                v.load_state_dict(sd[k])\n",
    "    else:\n",
    "        runner.load_state_dict(sd)\n",
    "    print('LOADED:', config.experiment.checkpoint_path)\n",
    "\n",
    "\n",
    "dataloaders_dict = dict()\n",
    "for dataloader_name, dataloader in dataloader_ms.items():\n",
    "    dataloaders_dict[dataloader_name] = dataloader.create_dataloader()\n",
    "\n",
    "dataloader_short = dataloaders_dict['short']\n",
    "dataloader_long = dataloaders_dict['long']\n",
    "\n",
    "sample_short = next(iter(dataloader_short))\n",
    "sample_long = next(iter(dataloader_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garment name ben_004::top_coat,ben_004::scarf\n",
      "sequence_name 144/144_26_poses.npz\n",
      "roll_steps 100\n",
      "Module utils.warp_u.proximity b91666f load on device 'cuda:0' took 0.88 ms  (cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug:  50%|█████     | 1/2 [00:32<00:32, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long saved to /local/home/agrigorev/Data/temp/debug/long_50001.pkl\n",
      "garment name ben_004::top_coat,ben_004::scarf\n",
      "sequence_name 144/144_26_poses.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ccraft_train_s1_debug: 100%|██████████| 2/2 [00:36<00:00, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short saved to /local/home/agrigorev/Data/temp/debug/short_50002.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = runner_module.run_epoch(runner, aux_modules, dataloaders_dict, config, None,\n",
    "                                global_step=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import pickle_load\n",
    "\n",
    "traj_path_new = '/local/home/agrigorev/Data/temp/debug/long_50001.pkl'\n",
    "traj_path_old = '/local/home/agrigorev/Data/temp/debug_old/long_50001.pkl'\n",
    "\n",
    "traj_new = pickle_load(traj_path_new)\n",
    "traj_old = pickle_load(traj_path_old)\n",
    "\n",
    "traj_old['metrics'] = {k[5:]: v for k, v in traj_old['metrics'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hood/stretching_energy_loss 0.3489467564970255 0.3008002529293299\n",
      "hood/bending_energy_loss 0.052061445642502806 0.06113392335770186\n",
      "hood/inertia_loss 0.005703017642517807 0.005532875381904887\n",
      "hood/gravitational_energy_loss 5.70411994278431 0.18318553576245905\n",
      "hood/collision_penalty_loss 1.7778491685324115e-06 3.893926055232442e-08\n",
      "hood/repulsion_loss 0.0 0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for k in traj_new['metrics'].keys():\n",
    "    print(k, traj_new['metrics'][k], traj_old['metrics'][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hood/stretching_energy_loss': 0.3489467564970255,\n",
       " 'hood/bending_energy_loss': 0.052061445642502806,\n",
       " 'hood/inertia_loss': 0.005703017642517807,\n",
       " 'hood/gravitational_energy_loss': 5.70411994278431,\n",
       " 'hood/collision_penalty_loss': 1.7778491685324115e-06,\n",
       " 'hood/repulsion_loss': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_new['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long/hood/stretching_energy_loss': 0.3008002529293299,\n",
       " 'long/hood/inertia_loss': 0.005532875381904887,\n",
       " 'long/hood/gravitational_energy_loss': 0.18318553576245905,\n",
       " 'long/hood/bending_energy_loss': 0.06113392335770186,\n",
       " 'long/hood/collision_penalty_loss': 3.893926055232442e-08,\n",
       " 'long/hood/repulsion_loss': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_old['metrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make debug datalists for new and old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_multig_novest.csv'\n",
    "old_datasplit = pd.read_csv(old_df_path)\n",
    "\n",
    "\n",
    "new_df_path = '/local/home/agrigorev/Data/02_Projects/ccraft_data/aux_data/datasplits/train_ccraft.csv'\n",
    "new_datasplit = pd.read_csv(new_df_path)\n",
    "new_row = new_datasplit.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2730"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(old_datasplit.length.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_datasplit_f1 = old_datasplit[old_datasplit.garment=='ben_004::top_coat,ben_004::scarf']\n",
    "old_row = old_datasplit_f1.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>garment</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29171</th>\n",
       "      <td>32707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tshirt_shape14_144_26</td>\n",
       "      <td>1480</td>\n",
       "      <td>ben_004::top_coat,ben_004::scarf</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0                     id  length  \\\n",
       "29171         32707         NaN  tshirt_shape14_144_26    1480   \n",
       "\n",
       "                                garment gender  \n",
       "29171  ben_004::top_coat,ben_004::scarf   male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row.to_csv('/local/home/agrigorev/Data/temp/datasplits/new.csv', index=False)\n",
    "old_row.to_csv('/local/home/agrigorev/Data/temp/datasplits/old.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/agrigorev/miniforge3/envs/ccraft/lib/python3.10/site-packages/torch_cluster/nearest.py:3: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  import scipy.cluster\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "a = Batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.short_is_training = True\n",
    "self.mcfg.long_is_training = True\n",
    "self.mcfg.nocollect_after = 2\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "\n",
    "```\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = self.safecheck\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "### config\n",
    "```python\n",
    "self.mcfg.no_world_edges_every = 2\n",
    "self.mcfg.nocollect_after = 2\n",
    "self.mcfg.short_is_training = True\n",
    "```\n",
    "\n",
    "\n",
    "### forward_short\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = (roll_steps == 1) or (i > 0)\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.short_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.short_is_training\n",
    "    if i == 0 and roll_steps > 1:\n",
    "        is_training = False\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### forward_long\n",
    "```python\n",
    "use_wedges_seq = True\n",
    "if self.mcfg.no_world_edges_every > 0 and self.short_steps % self.mcfg.no_world_edges_every == 0:\n",
    "    use_wedges_seq = False\n",
    "\n",
    "for i in range(roll_steps):\n",
    "    is_safecheck = False\n",
    "\n",
    "    use_wedges = True\n",
    "    use_wedges = use_wedges and use_wedges_seq\n",
    "    if not use_wedges:\n",
    "        is_safecheck = False\n",
    "\n",
    "    if self.mcfg.nocollect_after > 0:\n",
    "        is_training = self.mcfg.long_is_training and (i < self.mcfg.nocollect_after)\n",
    "    else:\n",
    "        is_training = self.mcfg.long_is_training\n",
    "\n",
    "    fake_icontour = not use_wedges\n",
    "\n",
    "    sample_step = self.model(sample_step, world_edges=use_wedges, is_training=is_training, fake_icontour=fake_icontour)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
